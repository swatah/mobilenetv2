{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546e6f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCopyright (c) 2025 NeuralSense AI Private Limited\\nTrading as swatah.ai. All rights reserved.\\nThis file is part of the swatah.ai software stack and is licensed under\\nthe terms defined in the accompanying LICENSE file. Unauthorized copying,\\ndistribution, or modification of this file, via any medium, is strictly prohibited.\\nFor more information, visit: https://swatah.ai\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copyright (c) 2025 NeuralSense AI Private Limited\n",
    "Trading as swatah.ai. All rights reserved.\n",
    "This file is part of the swatah.ai software stack and is licensed under\n",
    "the terms defined in the accompanying LICENSE file. Unauthorized copying,\n",
    "distribution, or modification of this file, via any medium, is strictly prohibited.\n",
    "For more information, visit: https://swatah.ai\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00766b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/radxa/dev/mobilenetv2\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b63ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ff79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b322d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, image_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    img = np.array(img).astype(np.float32) / 255.0\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a076ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(\"models/mobilenetv2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b03e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"images/Koala.jpg\"\n",
    "input_tensor = preprocess_image(img_path)\n",
    "outputs = session.run(None, {\"input\": input_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ee65c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class index: 105\n",
      "Predicted class name: koala\n"
     ]
    }
   ],
   "source": [
    "predicted_class = np.argmax(outputs[0])\n",
    "print(\"Predicted class index:\", predicted_class)\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "LABELS_URL = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "class_names = urllib.request.urlopen(LABELS_URL).read().decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "print(f\"Predicted class name: {class_names[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00818e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
